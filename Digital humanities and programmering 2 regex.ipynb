{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegEx and Frankenstein\n",
    "Online RegEx Tester: https://regex101.com/ is a helpful site for learning how to use regular expressions (Regex).\n",
    "\n",
    "W3schools also has a very useful page about RegEx. https://www.w3schools.com/python/python_regex.asp\n",
    "\n",
    "Regex's use is very widespread because RegEx is super smart in relation to text processing, because it can be used to perform advanced searches. RegEx is used for search engines and for search and replace functions. Working with RegEx is definitely an experience in itself, but when you get an insight into the scope of tasks that can be solved with RegEx, you realize that it is an incredibly good tool.\n",
    "\n",
    "This notebook doesn't try to teach you everything about RegEx, but it does try to create learning about it, and only a few of the possibilities are illustrated below.\n",
    "\n",
    "In addition to RegEx, this notebook contains many loops and list comprehensions, so that way you can also get an insight into how to write this sort of thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files\n",
    "We get the book Frankenstein from Project Gutenberg and use it for the rest of the workshop. We download the Plain Text UTF-8 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request \n",
    "url = 'https://gutenberg.org/cache/epub/84/pg84.txt'\n",
    "raw_text = urllib.request.urlopen(url).read().decode()\n",
    "text_start = raw_text.find('*** START OF THE PROJECT GUTENBERG EBOOK FRANKENSTEIN; OR, THE MODERN PROMETHEUS ***')\n",
    "text_start = text_start + len('*** START OF THE PROJECT GUTENBERG EBOOK FRANKENSTEIN; OR, THE MODERN PROMETHEUS ***')\n",
    "text_end = raw_text.find('*** END OF THE PROJECT GUTENBERG EBOOK FRANKENSTEIN; OR, THE MODERN PROMETHEUS ***')\n",
    "text = raw_text[text_start:text_end].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frankenstein;\\r\\n\\r\\nor, the Modern Prometheus\\r\\n\\r\\nby Mary Wollstonecraft (Godwin) Shelley\\r\\n\\r\\n\\r\\n CONTENTS'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metacharacters\n",
    "\n",
    "\\b \\S and \\w and the + sign\n",
    "\n",
    "These metadatacharacters are relevant when cleaning text data.\n",
    "\n",
    "Cleaning the text will often be a fundamental necessity before working on using different methods to analyze the text. Cleaning often consists of removing grammatical characters, ensuring that all uppercase letters are changed to lowercase, and that [stop words](https://en.wikipedia.org/wiki/Stop_word) have been filtered out.\n",
    "\n",
    "When we need to clean our text of grammatical characters, we use RegEX patterns and Python string methods. Below we test two different RegEX patterns.\n",
    "\n",
    "When we work with RegEx, the website [regex101.com](https://regex101.com/) is a brilliant tool, because we can get help partly to understand Regex, partly to write a Regex pattern.\n",
    "\n",
    "Try to open the page and insert this text string: _Chapter 1 I am by birth a Genevese, and my family is one of the most distinguished of that republic._ in the field 'TEXT STRING'.\n",
    "\n",
    "**First RegEX pattern '\\b\\S+\\b'**.\n",
    "\n",
    "In the 'REGULAR EXPRESSION' field you can write this pattern _'\\b\\S+\\b'_.\n",
    "\n",
    "\\b : \\b finds the position at the boundary of a word (word boundary). \\S: \\S matches any non-space +: + matches the previous character between one and an unlimited number of times, as many times as possible until the next character. They say the plus is greedy. \\b : \\b finds the position at the boundary of a word (word boundary).\n",
    "\n",
    "When you set \\b\\S+\\b, you match from, you match all \"non-space characters\" as well as underscores, but not symbols such as periods, commas, question marks.\n",
    "\n",
    "**Other RegEX pattern '\\w+'**.\n",
    "Another Regex pattern that is also used for cleaning is '\\w+'.\n",
    "\\w: \\w matches any alphabetic letter (uppercase and lowercase), any number, or an underscore (_). +: + matches the preceding character one or more times.\n",
    "\n",
    "When you put \\w+ together, you match whole words composed of letters, digits and underscores.\n",
    "\n",
    "**Comparison of the two RegEX patterns**\n",
    "\n",
    "In the first method, _There-for_ remains in a word\n",
    "\n",
    "In the second method it becomes two words, _There for_.\n",
    "\n",
    "Search e.g. after _About two o'clock_.\n",
    "\n",
    "In the first method, _o'clock_ remains a word.\n",
    "\n",
    "In the second method it becomes two words, _o clock_.\n",
    "\n",
    "Both methods leave us with underscores (_), so to get rid of underscores we use stitch's .replace() method.\n",
    "\n",
    "Try both methods below and inspect the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text_1(text):\n",
    "    # Use \\w+ regex pattern to extract words\n",
    "    words = re.findall(r'\\b\\S+\\b', text)\n",
    "\n",
    "    # Join the extracted words into a cleaned text\n",
    "    cleaned_text = ' '.join(words)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def clean_text_2(text):\n",
    "    # Use \\w+ regex pattern to extract words\n",
    "    words = re.findall(r'\\w+', text)\n",
    "\n",
    "    # Join the extracted words into a cleaned text\n",
    "    cleaned_text = ' '.join(words)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frankenstein or the Modern Prometheus by Mary Wollstonecraft Godwin Shelley CONTENTS Letter 1 Letter\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = clean_text_1(text)\n",
    "\n",
    "print(cleaned_text[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frankenstein or the Modern Prometheus by Mary Wollstonecraft Godwin Shelley CONTENTS Letter 1 Letter\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = clean_text_2(text)\n",
    "\n",
    "print(cleaned_text[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w+ along with \\b\n",
    "\n",
    "Find words with special endings, e.g. _day_, can be a help to gain insight into where and when the literature takes place.\n",
    "\n",
    "Why doesn't anything happen on a Friday?\n",
    "\n",
    "You can also use the endings to find grammatical forms, e.g. words with a long affix will be relatively easy to identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yesterday', 'holiday', 'Monday', 'Yesterday', 'Sunday', 'Thursday', 'today', 'today', 'yesterday', 'yesterday', 'everyday']\n"
     ]
    }
   ],
   "source": [
    "ending = re.findall(r'\\w+day\\b', text)\n",
    "print(ending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More metacharacters, as well as pipes, lists and question marks\n",
    "\n",
    "In literature, comparisons are often used to illustrate points more clearly by putting pictures on what you want to describe. Comparisons also contribute to making the text more lively and interesting.\n",
    "\n",
    "But regex makes it a manageable task to retrieve examples of comparisons in Grimm's fairy tales, because we can find text strings that follow the pattern of a typical comparison.\n",
    "\n",
    "We can illustrate it in the following way. We look for phrases whose pattern is either as a ... or as an ....\n",
    "\n",
    "The RegEx pattern can be written like this:\n",
    "\n",
    "'as\\sa\\s\\w+'\n",
    "\n",
    "The word 'as' is followed by \\s, meaning white space, followed by a, then followed by \\s, followed by \\w, meaning word charater, followed by + meaning \"one or more of the previous\".\n",
    "\n",
    "\n",
    "If you also want to search for \"as an ...\" there are two ways to do it.\n",
    "\n",
    "\n",
    "First way is to use pipe |. Pipe means \"or\". The regex pattern will then look like this: 'as\\sa\\s\\w+|as\\san\\s\\w+'\n",
    "\n",
    "Another way is to use the square brackets [ ].\n",
    "\n",
    "It looks like this: 'as\\sa[n]?\\s\\w+'. In the list, letters can be added that can stand in that place in the word. The question mark indicates that the letter may or may not be there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['as a steady', 'as a child', 'as a most', 'as a Turk', 'as a remarkably', 'as a human', 'as a little', 'as a brother', 'as a double', 'as a halo', 'as a merchant', 'as a considerable', 'as a sense', 'as a show', 'as a fair', 'as a restorative', 'as a necessity', 'as a German', 'as a boy', 'as a promise', 'as a deformed', 'as a strong', 'as a narrow', 'as a little', 'as a dream', 'as a certain', 'as a bold', 'as a mystery', 'as a most', 'as a proof', 'as a tendency', 'as a divine', 'as a widow', 'as a servant', 'as a great', 'as a judgement', 'as a Roman', 'as a miniature', 'as a new', 'as a strange', 'as a girl', 'as a proof', 'as a dire', 'as a murderer', 'as a wretch', 'as a creature', 'as a murderess', 'as a wreck', 'as a lullaby', 'as a poor', 'as a new', 'as a little', 'as a small', 'as a lovely', 'as a lady', 'as a guide', 'as a vagabond', 'as a Turkish', 'as a Christian', 'as a boarder', 'as a distant', 'as a listener', 'as a true', 'as a luxury', 'as a fool', 'as a recompense', 'as a portrait', 'as a right', 'as a being', 'as a scene', 'as a soul', 'as a being', 'as a new', 'as a place', 'as a monotonous', 'as a reality', 'as a task', 'as a thing', 'as a place', 'as a very', 'as a hired', 'as a dream', 'as a new', 'as a presumption', 'as a momentary', 'as a criminal', 'as a torpor', 'as a shattered', 'as a mere', 'as a delusion', 'as a mockery', 'as a great', 'as a magistrate', 'as a man', 'as a beast', 'as a frenzy', 'as a nurse', 'as a task', 'as a week', 'as a southern', 'as a rock']\n"
     ]
    }
   ],
   "source": [
    "comparison = re.findall(r'as\\sa\\s\\w+', cleaned_text)\n",
    "print (comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['as a steady', 'as a child', 'as an under', 'as a most', 'as a Turk', 'as a remarkably', 'as a human', 'as a little', 'as a brother', 'as a double', 'as a halo', 'as a merchant', 'as a considerable', 'as a sense', 'as a show', 'as a fair', 'as a restorative', 'as an infant', 'as a necessity', 'as a German', 'as a boy', 'as an inferior', 'as a promise', 'as a deformed', 'as a strong', 'as a narrow', 'as an uncouth', 'as a little', 'as a dream', 'as a certain', 'as an easier', 'as a bold', 'as a mystery', 'as a most', 'as a proof', 'as a tendency', 'as a divine', 'as an odious', 'as a widow', 'as a servant', 'as a great', 'as a judgement', 'as a Roman', 'as an irresistible', 'as an historical', 'as an air', 'as a miniature', 'as a new', 'as a strange', 'as a girl', 'as a proof', 'as a dire', 'as a murderer', 'as a wretch', 'as a creature', 'as a murderess', 'as a wreck', 'as a lullaby', 'as a poor', 'as a new', 'as a little', 'as a small', 'as a lovely', 'as a lady', 'as a guide', 'as a vagabond', 'as a Turkish', 'as a Christian', 'as a boarder', 'as a distant', 'as a listener', 'as a true', 'as an excellent', 'as a luxury', 'as a fool', 'as a recompense', 'as a portrait', 'as a right', 'as a being', 'as a scene', 'as a soul', 'as a being', 'as an extreme', 'as a new', 'as a place', 'as a monotonous', 'as an insuperable', 'as a reality', 'as a task', 'as a thing', 'as a place', 'as a very', 'as a hired', 'as a dream', 'as a new', 'as a presumption', 'as a momentary', 'as an agitation', 'as a criminal', 'as a torpor', 'as a shattered', 'as a mere', 'as an event', 'as a delusion', 'as an occurrence', 'as a mockery', 'as a great', 'as a magistrate', 'as a man', 'as a beast', 'as a frenzy', 'as a nurse', 'as a task', 'as a week', 'as a southern', 'as a rock']\n"
     ]
    }
   ],
   "source": [
    "comparison = re.findall(r'as\\sa\\s\\w+|as\\san\\s\\w+', cleaned_text)\n",
    "print (comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['as a steady', 'as a child', 'as an under', 'as a most', 'as a Turk', 'as a remarkably', 'as a human', 'as a little', 'as a brother', 'as a double', 'as a halo', 'as a merchant', 'as a considerable', 'as a sense', 'as a show', 'as a fair', 'as a restorative', 'as an infant', 'as a necessity', 'as a German', 'as a boy', 'as an inferior', 'as a promise', 'as a deformed', 'as a strong', 'as a narrow', 'as an uncouth', 'as a little', 'as a dream', 'as a certain', 'as an easier', 'as a bold', 'as a mystery', 'as a most', 'as a proof', 'as a tendency', 'as a divine', 'as an odious', 'as a widow', 'as a servant', 'as a great', 'as a judgement', 'as a Roman', 'as an irresistible', 'as an historical', 'as an air', 'as a miniature', 'as a new', 'as a strange', 'as a girl', 'as a proof', 'as a dire', 'as a murderer', 'as a wretch', 'as a creature', 'as a murderess', 'as a wreck', 'as a lullaby', 'as a poor', 'as a new', 'as a little', 'as a small', 'as a lovely', 'as a lady', 'as a guide', 'as a vagabond', 'as a Turkish', 'as a Christian', 'as a boarder', 'as a distant', 'as a listener', 'as a true', 'as an excellent', 'as a luxury', 'as a fool', 'as a recompense', 'as a portrait', 'as a right', 'as a being', 'as a scene', 'as a soul', 'as a being', 'as an extreme', 'as a new', 'as a place', 'as a monotonous', 'as an insuperable', 'as a reality', 'as a task', 'as a thing', 'as a place', 'as a very', 'as a hired', 'as a dream', 'as a new', 'as a presumption', 'as a momentary', 'as an agitation', 'as a criminal', 'as a torpor', 'as a shattered', 'as a mere', 'as an event', 'as a delusion', 'as an occurrence', 'as a mockery', 'as a great', 'as a magistrate', 'as a man', 'as a beast', 'as a frenzy', 'as a nurse', 'as a task', 'as a week', 'as a southern', 'as a rock']\n"
     ]
    }
   ],
   "source": [
    "comparison = re.findall(r'as\\sa[n]?\\s\\w+', cleaned_text)\n",
    "print (comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curly brackets\n",
    "\n",
    "Curly brackets are for example relevant when making a concordance (word and context).\n",
    "\n",
    "We want to find excerpts of text that contain storm, because we are actually interested in pointing down in the text and seeing how exactly the terms are used.\n",
    "\n",
    "For this we need to use the full stop ( . ) because it gives us more word characters and {30} searches for us to get 30 word characters before we hit the letters Turk.\n",
    "\n",
    "The period {30} after Turk gives us another 30 word characters.\n",
    "\n",
    "Try to see if you can use some of what has been reviewed above to include text extracts that contain the word Roman.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['st be his story frightful the storm which embraced the gallant ve',\n",
       " 't violent and terrible thunderstorm It advanced from behind the m',\n",
       " ' heavens I remained while the storm lasted watching its progress ',\n",
       " ' of preservation to avert the storm that was even then hanging in',\n",
       " 'he most beautiful figures The storm appeared to approach rapidly ',\n",
       " ' on although the darkness and storm increased every minute and th',\n",
       " ' from the preceding flash The storm as is often the case in Switz',\n",
       " ' the heavens The most violent storm hung exactly north of the tow',\n",
       " ' the village of Copêt Another storm enlightened Jura with faint f',\n",
       " 'y retreats What were rain and storm to me My mule was brought to ',\n",
       " 'ning to rise Suddenly a heavy storm of rain descended I had been ']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'.{30}storm.{30}', cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Square brackets [A-Z]\n",
    "\n",
    "Find words that start with capital letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frankenstein', 'Modern', 'Prometheus', 'Mary', 'Wollstonecraft', 'Godwin', 'Shelley', 'CONTENTS', 'Letter', 'Letter', 'Letter', 'Letter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Letter', 'To', 'Mrs', 'Saville', 'England', 'St', 'Petersburgh', 'Dec', 'You', 'London', 'Petersburgh', 'Do', 'This', 'Inspirited', 'There', 'Margaret', 'There', 'Its', 'What', 'These', 'But', 'These', 'This', 'North', 'Pacific', 'Ocean', 'You', 'Uncle', 'Thomas', 'My', 'These', 'These', 'Homer', 'Shakespeare', 'You', 'But', 'Six', 'North', 'Sea', 'Twice', 'Greenland', 'And', 'Margaret', 'My', 'Oh', 'My', 'This', 'Russia', 'They', 'English', 'The', 'St', 'Petersburgh', 'Archangel', 'June', 'Ah', 'If', 'If', 'Farewell', 'Margaret', 'Heaven', 'Your', 'Walton', 'Letter']\n"
     ]
    }
   ],
   "source": [
    "upper_case_word = re.findall(r'[A-Z]\\w+', text)\n",
    "print (upper_case_word[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mange af disse ord er skrevet med stort, fordi de optræder efter et punktum, og på den måde er de ikke, hvad jeg vil kalde for \"ægte\" ord med stort.\n",
    "\n",
    "Hvis man vil bortfiltrere de \"uægte\" ord fra sin liste, så kan man afsløre dem ved at lave et loop og indsætte en betingelse, der kan tjekke om, ordene skulle være skrevet med småt andre steder i teksterne, fordi hvis de er det, så er de \"uægte\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Frankenstein', 'Prometheus', 'Mary', 'Wollstonecraft', 'Godwin', 'Shelley', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Chapter', 'Mrs', 'Saville', 'England', 'Petersburgh', 'London', 'Petersburgh', 'Margaret', 'Pacific', 'Thomas', 'Homer', 'Shakespeare', 'Greenland', 'Margaret', 'Russia', 'English', 'Petersburgh', 'June', 'Ah', 'Margaret', 'Walton', 'Mrs', 'Saville', 'England', 'Margaret', 'Thomas', 'Englishman', 'Russian', 'Turk', 'Africa', 'America', 'Robert', 'Walton', 'Mrs', 'Saville', 'England', 'July', 'England', 'England', 'Adieu', 'Margaret', 'Mrs', 'Saville', 'England', 'August', 'Monday', 'July', 'European', 'English', 'Margaret', 'Margaret', 'August', 'August', 'Walton', 'Chapter', 'Genevese', 'Beaufort', 'Lucerne', 'Beaufort', 'Beaufort', 'Reuss', 'Beaufort', 'Caroline', 'Beaufort', 'Beaufort', 'Geneva', 'Caroline', 'Italy', 'Italy', 'Germany', 'France']\n"
     ]
    }
   ],
   "source": [
    "true_upper_case = []\n",
    "for word in upper_case_word:\n",
    "    if word.lower() not in text:\n",
    "        true_upper_case.append(word)\n",
    "print (true_upper_case[0:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
